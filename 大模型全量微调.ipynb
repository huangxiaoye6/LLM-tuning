{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3360617c-1dcd-45e7-a108-488eabd80576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-13 19:21:21,779] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0613 19:21:23.055000 8720 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-13 19:21:23,514] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel,AutoTokenizer,pipeline,Trainer,TrainingArguments,AutoModelForCausalLM,default_data_collator\n",
    "from datasets import Dataset, load_dataset\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bade1d-5a46-4ae5-af37-b5351e949d65",
   "metadata": {},
   "source": [
    "### 加载模型和分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b51fe34c-b437-4658-a2f3-369242dcf560",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"Qwen/Qwen3-0.6B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4c63c31-af31-4496-9cdf-a8e9dcc94e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    # trust_remote_code=True,\n",
    "    device_map='auto',\n",
    "    torch_dtype=\"auto\",\n",
    ")\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token=tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eec1357-4113-4057-b1a7-61d18afaf30a",
   "metadata": {},
   "source": [
    "### 加载训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be5126f1-d931-4b76-a6b9-7a960a048f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('json', data_files={\n",
    "    'train': '../数据集/data/train.json',\n",
    "    'validation': '../数据集/data/eval.json'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f98d257d-94a4-4033-9a82-ff653be6e5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集加载成功，包含以下部分: ['train', 'validation']\n",
      "训练数据集加载成功，包含 320 个样本\n",
      "验证数据集加载成功，包含 30 个样本\n"
     ]
    }
   ],
   "source": [
    "print(f\"数据集加载成功，包含以下部分: {list(dataset.keys())}\")\n",
    "print(f\"训练数据集加载成功，包含 {len(dataset['train'])} 个样本\")\n",
    "print(f\"验证数据集加载成功，包含 {len(dataset['validation'])} 个样本\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fd0f1da-02e4-4f1f-862a-d6b24d87975f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据集示例: {'conversations': [{'from': 'human', 'value': '请问室温超导技术的难点在哪里,人类在什么时候可以实现室温超导?'}, {'from': 'gpt', 'value': '室温超导技术的难点在于目前尚未发现或创造出能在室温下保持超导性的材料。常见的超导体需要在极低温（如液氦温度，约-269°C）下才能表现出零电阻和完全抗磁性的超导特性。尽管科学家们在高温超导材料研究方面取得了进展，目前已知的高温超导体在实现超导状态时所需的温度仍远远低于室温。\\n\\n实现室温超导的难点主要有以下几个方面：\\n\\n1. 材料问题：高温超导体多为陶瓷材料，这类材料往往脆弱难以制成长导线，并且许多超导材料在高温、高压条件下稳定性较差。\\n\\n2. 理论挑战：超导机制通常基于量子物理理论。对于传统的低温超导体，BCS理论（巴丁-库珀-施里弗理论）能够很好地描述其超导机制。但对于高温超导体，至今还没有一个普遍认可且完整的理论框架。\\n\\n3. 技术限制：即使找到合适的材料或者理论模型，通过现有的技术制备高质量的样品也是非常困难的。要保持超导状态需要的一系列条件如纯度、晶格结构的完整性等，在室温下实现和维持更加困难。\\n\\n4. 经济和实用性：即便科学家们能发现或制造出在室温下工作的超导材料，但其制造成本、可持续性和实际应用的有效性都是可能的挑战。\\n\\n至于人类能在什么时候实现室温超导，目前无法给出一个确切的时间表。室温超导是物理学中的一个激动人心但又极具挑战性的前沿议题，其研究进展依赖于新材料的发现、理论物理的突破以及实验技术的进步。可以说，室温超导的实现还处于科学探索的阶段，是未来技术发展具有重要潜力的领域之一。'}, {'from': 'human', 'value': '可以列出5样稀有金属吗？请按全球需求来排名'}, {'from': 'gpt', 'value': '稀有金属指的是地壳中含量较少、分布不均或开采困难的金属元素，它们在高科技领域和新兴工业中扮演着非常重要的角色。全球需求的排序可能因时间和技术进步而变化，但以下是通常被广泛需求的一些稀有金属（不一定按绝对的需求量排名，因为这在不同时间点可能不同）：\\n\\n1. **钴(Cobalt, Co)** - 钴是锂离子电池的关键成分之一，尤其是在电动汽车和便携式电子产品中。此外，它也被应用于耐热合金、硬质合金以及催化剂的制造。\\n\\n2. **钕(Neodymium, Nd)** - 钕是一种稀土金属，主要用于强磁体的生产，比如高性能的永磁体，这些永磁体广泛用于计算机硬盘、风力涡轮机和电动汽车的驱动电机中。\\n\\n3. **锂(Lithium, Li)** - 锂主要用于锂电池的制造，随着电动车和便携式电子设备的需求增加，锂的需求量迅速上升。\\n\\n4. **银(Silver, Ag)** - 虽然银不像上述金属那样稀有，但其在工业中的需求量巨大，主要用于电子产品、太阳能面板、珠宝和货币制造等领域。\\n\\n5. **钌(Ruthenium, Ru)** - 钌是一种稀有贵金属，被广泛使用在硬盘驱动器的数据储存及大容量服务器中，同时也用在催化剂和电化学电池中。\\n\\n这些金属的需求量受到了全球经济、科技发展和政策支持等多方面因素的影响。而且随着时间的推移和市场的变化，其他稀有金属如钽、铟、铼以及其他的稀土金属，也可能出现在最受需求的稀有金属列表中。'}]}\n"
     ]
    }
   ],
   "source": [
    "print(f\"训练数据集示例: {dataset['train'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d60294d9-96d0-4fbf-a05c-b8db9a9a3371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证数据集示例: {'conversations': [{'from': 'human', 'value': '我想系统的学习编程，该如何开始？'}, {'from': 'gpt', 'value': '系统地学习编程非常重要，以下是一些步骤和建议帮助你开始：\\n\\n### 1. 选择编程语言\\n开始学习编程之前，你需要选择一门编程语言。对于初学者来说，常推荐的语言包括Python、JavaScript、Ruby或Java。Python由于其简洁的语法和强大的社区支持，通常是入门的首选。\\n\\n### 2. 理解编程基础\\n不论选择哪种语言，都应从基础概念开始学习，如：\\n- 数据类型和变量\\n- 控制结构（条件语句、循环）\\n- 数据结构（数组、列表、字典）\\n- 函数/方法\\n- 类和对象（面向对象编程的基本）\\n\\n### 3. 搭建开发环境\\n- 为你选择的语言安装编译器或解释器。\\n- 安装文本编辑器或集成开发环境（IDE），例如Visual Studio Code、PyCharm或Eclipse。\\n\\n### 4. 实践编码\\n- 开始写简单的程序，实践你所学的概念。\\n- 尝试解决一些基本的编程问题，例如LeetCode、HackerRank或Codecademy上的挑战。\\n\\n### 5. 学习版本控制\\n- 学习使用Git，并熟悉GitHub或其他代码托管平台，以便管理你的代码版本和参与开源项目。\\n\\n### 6. 开始小项目\\n- 一边学习，一边开始一个小项目，比如一个个人博客、一个简单的游戏或者一个数据分析的小工具。\\n- 实际动手解决问题能增强你的学习经验和解决问题的能力。\\n\\n### 7. 学习计算机科学原理\\n- 学习计算机科学的基础，如算法和数据结构，这会帮助你写出更高效、可维护的代码。\\n- 了解操作系统、网络和数据库的基础知识也非常重要。\\n\\n### 8. 参考优质资源\\n- 书籍：找一些好评如潮的编程书籍开始阅读，如《Python编程：从入门到实践》、《JavaScript高级程序设计》等。\\n- 在线课程：Udemy、Coursera、edX 提供了非常多的在线课程。\\n- 视频教程：YouTube、B站等平台有很多免费的编程教程。\\n\\n### 9. 加入社区\\n- 加入Stack Overflow、Reddit、编程相关的论坛和社交媒体群组。\\n- 参加线上或线下的编程Meetups和Hackathons。\\n\\n### 10. 持续学习和挑战自己\\n- 保持好奇心，不断地学习新技术、新框架。\\n- 阅读开源项目的代码，甚至尝试为开源项目做贡献。\\n\\n系统学习编程是一个长期、不断进步的过程。保持耐心和毅力，不断实践和积累经验，你就会广泛提升编程能力。'}, {'from': 'human', 'value': '虽然你说的看上去有点道理，但是你这段话明显是从哪个营销号上复制粘贴过来的啊，连后面几段原作者用来自我宣传的广告都没去掉。'}, {'from': 'gpt', 'value': '抱歉给你带来不愉快的体验。那么我们重新梳理一下编程学习的步骤：\\n\\n1. **确定学习目标：**了解编程领域的不同方向，比如前端、后端、移动应用、数据科学、人工智能等，并选择符合你兴趣和职业规划的方向。\\n\\n2. **选择编程语言：**根据学习目标选择一门适合的语言开始。例如，学习前端可以从HTML, CSS, JavaScript开始，学习后端则可以选择Python、Java或者Node.js等。\\n\\n3. **获取学习资源：**找到高质量的学习资源，包括书籍、在线课程、教学视频、技术文档、编程社区和论坛等。资源的选择要根据自己的学习风格和需要来定。\\n\\n4. **理解基本概念：**在开始具体的编程前，先了解编程的一些基础知识，如变量、数据类型、控制结构、数组、函数等。\\n\\n5. **实践编码：**理论知识只有通过实践来巩固。你可以开始写一些简单的程序，然后不断挑战更复杂的项目。\\n\\n6. **学习使用工具：**学会使用开发工具，如文本编辑器、IDE（集成开发环境）、版本控制系统（如Git）、调试工具等。\\n\\n7. **构建项目：**创建个人项目或参与开源项目。这不仅帮助你在实际场景中应用所学知识，还能增强你的问题解决能力。\\n\\n8. **加入社区：**参与编程论坛和社区，如GitHub、Stack Overflow、Reddit的编程相关子版块等，可以让你学习到更多、更实际的技术，也有助于建立联系和了解行业动态。\\n\\n9. **不断进阶：**在完成基础学习后，不断拓展知识面，学习高级概念和框架、设计模式、算法与数据结构等内容。\\n\\n10. **持续实践和复习：**编程技术在不断变化，所以需要不断实践和复习，保持知识的更新和技能的锐利。\\n\\n遵循上述步骤，你可以更系统地学习编程，并逐步积累经验，最终成为一名合格的程序员。记住，编程是一项实践性很强的技能，不断写代码和构建项目是提升的不二法门。'}]}\n"
     ]
    }
   ],
   "source": [
    "print(f\"验证数据集示例: {dataset['validation'][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c428bb-16f7-4247-aeb9-ed70610c73ca",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1a92889-cedf-4e2a-820d-1a95275b05c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fun(example):\n",
    "    question=[]\n",
    "    answer=[]\n",
    "    for i in example['conversations']:\n",
    "        for j in i:\n",
    "            if j['from']=='human':\n",
    "                question.append(j['value'])\n",
    "            elif j['from']=='gpt':\n",
    "                answer.append(j['value'])\n",
    "    return {'question':question,'answer':answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24ac6e60-07e8-423b-a275-1c430fa1f822",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data=dataset.map(process_fun,batched=True,remove_columns=dataset['train'].column_names) # 提取问题和答案数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07d354e-c50e-48cb-80b8-54ebe6848ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_fun(examples):\n",
    "    # 构建完整的指令格式（问：{问题}\\n答：{答案}）\n",
    "    instructions = []\n",
    "    for q, a in zip(examples['question'], examples['answer']):\n",
    "        instruction = f\"问：{q}\\n答：{a}\"\n",
    "        instructions.append(instruction)\n",
    "    \n",
    "    encoded = tokenizer(\n",
    "        instructions,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    labels = encoded[\"input_ids\"].clone()\n",
    "    \n",
    "    # 定位\"答：\"的位置，标记需要预测的部分\n",
    "    answer_start_token = tokenizer.encode(\"答：\", add_special_tokens=False)[0]\n",
    "    \n",
    "    # 遍历批次中的每个样本\n",
    "    for i in range(len(labels)):\n",
    "        # 找到每个样本中\"答：\"的第一个token位置\n",
    "        answer_positions = (labels[i] == answer_start_token).nonzero(as_tuple=True)[0]\n",
    "        if len(answer_positions) > 0:\n",
    "            # 只取第一个\"答：\"的位置\n",
    "            first_answer_pos = answer_positions[0]\n",
    "            # 将\"答：\"之前的token标记为-100（忽略计算损失）\n",
    "            labels[i, :first_answer_pos] = -100\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": encoded[\"input_ids\"],\n",
    "        \"attention_mask\": encoded[\"attention_mask\"],\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "012d1bab-6e11-4d7a-80f6-f7077c6c6dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = process_data.map(\n",
    "    tokenizer_fun,\n",
    "    batched=True,\n",
    "    remove_columns=process_data['train'].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a796d237-692d-47c8-90f6-9d9245627b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 606\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 52\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83d34b0-606d-44db-919a-b350b9476984",
   "metadata": {},
   "source": [
    "### 训练超参数配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff91b790-aaff-4d48-9a95-029450c6c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./train_qwen_0.6B_model\",\n",
    "    logging_steps=100,\n",
    "    logging_dir='./runs',\n",
    "    eval_strategy='epoch',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_loss',\n",
    "    gradient_accumulation_steps=4,  # 如果GPU内存有限\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7ffa1d-e707-4228-bfb8-0deef784af4c",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c5a7c08-33a4-4316-9662-13bd6f2ee8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    data_collator=default_data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0819cd1a-e1d1-4df5-b4b3-04d4bc8ed80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='114' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 1:11:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.402303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.392737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.439400</td>\n",
       "      <td>1.391980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=114, training_loss=1.4139219585217928, metrics={'train_runtime': 4291.1831, 'train_samples_per_second': 0.424, 'train_steps_per_second': 0.027, 'total_flos': 2459964933144576.0, 'train_loss': 1.4139219585217928, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dde64fee-7030-493f-bd7a-d1fe964f5924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#手动保存模型\n",
    "trainer.save_model('./train_qwen')\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4d6b1a-c71b-43de-982c-c9cd14ccd558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
