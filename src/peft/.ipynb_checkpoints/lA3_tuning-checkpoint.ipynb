{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# IA3微调",
   "id": "5ceb9e5a5a6755d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T11:06:32.761250Z",
     "start_time": "2026-02-12T11:06:27.080328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from peft import IA3Config,get_peft_model,TaskType\n",
    "from transformers import AutoModelForCausalLM,AutoTokenizer,TrainingArguments,Trainer,default_data_collator\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "65940f724ce320f4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "E:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1、加载模型和分词器",
   "id": "b7cc4a556e63be90"
  },
  {
   "cell_type": "code",
   "id": "9d4a7414-c30a-438a-ac96-70d637cfedb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T11:08:35.240500Z",
     "start_time": "2026-02-12T11:06:32.826403Z"
    }
   },
   "source": [
    "model_name=\"Qwen/Qwen3-0.6B\"\n",
    "model=AutoModelForCausalLM.from_pretrained(model_name,device_map='auto',torch_dtype=\"auto\",)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_name)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 311/311 [00:00<00:00, 418.16it/s, Materializing param=model.norm.weight]                              \n",
      "The tied weights mapping and config for this model specifies to tie model.embed_tokens.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
     ]
    },
    {
     "ename": "ConnectTimeout",
     "evalue": "timed out",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mConnectTimeout\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:101\u001B[0m, in \u001B[0;36mmap_httpcore_exceptions\u001B[1;34m()\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 101\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:250\u001B[0m, in \u001B[0;36mHTTPTransport.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[1;32m--> 250\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resp\u001B[38;5;241m.\u001B[39mstream, typing\u001B[38;5;241m.\u001B[39mIterable)\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001B[0m, in \u001B[0;36mConnectionPool.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    255\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_connections(closing)\n\u001B[1;32m--> 256\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    258\u001B[0m \u001B[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001B[39;00m\n\u001B[0;32m    259\u001B[0m \u001B[38;5;66;03m# the point at which the response is closed.\u001B[39;00m\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001B[0m, in \u001B[0;36mConnectionPool.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    234\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    235\u001B[0m     \u001B[38;5;66;03m# Send the request on the assigned connection.\u001B[39;00m\n\u001B[1;32m--> 236\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    237\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpool_request\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\n\u001B[0;32m    238\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    239\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ConnectionNotAvailable:\n\u001B[0;32m    240\u001B[0m     \u001B[38;5;66;03m# In some cases a connection may initially be available to\u001B[39;00m\n\u001B[0;32m    241\u001B[0m     \u001B[38;5;66;03m# handle a request, but then become unavailable.\u001B[39;00m\n\u001B[0;32m    242\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m    243\u001B[0m     \u001B[38;5;66;03m# In this case we clear the connection and try again.\u001B[39;00m\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001B[0m, in \u001B[0;36mHTTPConnection.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connect_failed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 101\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection\u001B[38;5;241m.\u001B[39mhandle_request(request)\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\httpcore\\_sync\\connection.py:78\u001B[0m, in \u001B[0;36mHTTPConnection.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 78\u001B[0m     stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_connect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     80\u001B[0m     ssl_object \u001B[38;5;241m=\u001B[39m stream\u001B[38;5;241m.\u001B[39mget_extra_info(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mssl_object\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\httpcore\\_sync\\connection.py:124\u001B[0m, in \u001B[0;36mHTTPConnection._connect\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconnect_tcp\u001B[39m\u001B[38;5;124m\"\u001B[39m, logger, request, kwargs) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[1;32m--> 124\u001B[0m     stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_network_backend\u001B[38;5;241m.\u001B[39mconnect_tcp(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    125\u001B[0m     trace\u001B[38;5;241m.\u001B[39mreturn_value \u001B[38;5;241m=\u001B[39m stream\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\httpcore\\_backends\\sync.py:207\u001B[0m, in \u001B[0;36mSyncBackend.connect_tcp\u001B[1;34m(self, host, port, timeout, local_address, socket_options)\u001B[0m\n\u001B[0;32m    202\u001B[0m exc_map: ExceptionMapping \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    203\u001B[0m     socket\u001B[38;5;241m.\u001B[39mtimeout: ConnectTimeout,\n\u001B[0;32m    204\u001B[0m     \u001B[38;5;167;01mOSError\u001B[39;00m: ConnectError,\n\u001B[0;32m    205\u001B[0m }\n\u001B[1;32m--> 207\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[0;32m    208\u001B[0m     sock \u001B[38;5;241m=\u001B[39m socket\u001B[38;5;241m.\u001B[39mcreate_connection(\n\u001B[0;32m    209\u001B[0m         address,\n\u001B[0;32m    210\u001B[0m         timeout,\n\u001B[0;32m    211\u001B[0m         source_address\u001B[38;5;241m=\u001B[39msource_address,\n\u001B[0;32m    212\u001B[0m     )\n",
      "File \u001B[1;32mD:\\Python\\lib\\contextlib.py:153\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__exit__\u001B[1;34m(self, typ, value, traceback)\u001B[0m\n\u001B[0;32m    152\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 153\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mthrow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtyp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraceback\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m    155\u001B[0m     \u001B[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001B[39;00m\n\u001B[0;32m    156\u001B[0m     \u001B[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001B[39;00m\n\u001B[0;32m    157\u001B[0m     \u001B[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001B[39;00m\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\httpcore\\_exceptions.py:14\u001B[0m, in \u001B[0;36mmap_exceptions\u001B[1;34m(map)\u001B[0m\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(exc, from_exc):\n\u001B[1;32m---> 14\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m to_exc(exc) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mexc\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[1;31mConnectTimeout\u001B[0m: timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mConnectTimeout\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m model_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mQwen/Qwen3-0.6B\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      2\u001B[0m model\u001B[38;5;241m=\u001B[39mAutoModelForCausalLM\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_name,device_map\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m,torch_dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m,)\n\u001B[1;32m----> 3\u001B[0m tokenizer\u001B[38;5;241m=\u001B[39m\u001B[43mAutoTokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:701\u001B[0m, in \u001B[0;36mAutoTokenizer.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m    698\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tokenizer_class \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    699\u001B[0m         tokenizer_class \u001B[38;5;241m=\u001B[39m TokenizersBackend\n\u001B[1;32m--> 701\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tokenizer_class\u001B[38;5;241m.\u001B[39mfrom_pretrained(pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(config, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtokenizer_class\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    703\u001B[0m     _class \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mtokenizer_class\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1646\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1644\u001B[0m             vocab_files[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchat_template_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtemplate_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mCHAT_TEMPLATE_DIR\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtemplate_file\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1645\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1646\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m template \u001B[38;5;129;01min\u001B[39;00m \u001B[43mlist_repo_templates\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1647\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1648\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1649\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1650\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1651\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1652\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1653\u001B[0m         template \u001B[38;5;241m=\u001B[39m template\u001B[38;5;241m.\u001B[39mremovesuffix(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.jinja\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1654\u001B[0m         vocab_files[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchat_template_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtemplate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mCHAT_TEMPLATE_DIR\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtemplate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.jinja\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\transformers\\utils\\hub.py:131\u001B[0m, in \u001B[0;36mlist_repo_templates\u001B[1;34m(repo_id, local_files_only, revision, cache_dir, token)\u001B[0m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m local_files_only:\n\u001B[0;32m    130\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 131\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[0;32m    132\u001B[0m             entry\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mremoveprefix(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mCHAT_TEMPLATE_DIR\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    133\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m entry \u001B[38;5;129;01min\u001B[39;00m list_repo_tree(\n\u001B[0;32m    134\u001B[0m                 repo_id\u001B[38;5;241m=\u001B[39mrepo_id,\n\u001B[0;32m    135\u001B[0m                 revision\u001B[38;5;241m=\u001B[39mrevision,\n\u001B[0;32m    136\u001B[0m                 path_in_repo\u001B[38;5;241m=\u001B[39mCHAT_TEMPLATE_DIR,\n\u001B[0;32m    137\u001B[0m                 recursive\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    138\u001B[0m                 token\u001B[38;5;241m=\u001B[39mtoken,\n\u001B[0;32m    139\u001B[0m             )\n\u001B[0;32m    140\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m entry\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.jinja\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    141\u001B[0m         ]\n\u001B[0;32m    142\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (GatedRepoError, RepositoryNotFoundError, RevisionNotFoundError):\n\u001B[0;32m    143\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m  \u001B[38;5;66;03m# valid errors => do not catch\u001B[39;00m\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\transformers\\utils\\hub.py:131\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m local_files_only:\n\u001B[0;32m    130\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 131\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[0;32m    132\u001B[0m             entry\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mremoveprefix(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mCHAT_TEMPLATE_DIR\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    133\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m entry \u001B[38;5;129;01min\u001B[39;00m list_repo_tree(\n\u001B[0;32m    134\u001B[0m                 repo_id\u001B[38;5;241m=\u001B[39mrepo_id,\n\u001B[0;32m    135\u001B[0m                 revision\u001B[38;5;241m=\u001B[39mrevision,\n\u001B[0;32m    136\u001B[0m                 path_in_repo\u001B[38;5;241m=\u001B[39mCHAT_TEMPLATE_DIR,\n\u001B[0;32m    137\u001B[0m                 recursive\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    138\u001B[0m                 token\u001B[38;5;241m=\u001B[39mtoken,\n\u001B[0;32m    139\u001B[0m             )\n\u001B[0;32m    140\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m entry\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.jinja\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    141\u001B[0m         ]\n\u001B[0;32m    142\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (GatedRepoError, RepositoryNotFoundError, RevisionNotFoundError):\n\u001B[0;32m    143\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m  \u001B[38;5;66;03m# valid errors => do not catch\u001B[39;00m\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\huggingface_hub\\hf_api.py:3321\u001B[0m, in \u001B[0;36mHfApi.list_repo_tree\u001B[1;34m(self, repo_id, path_in_repo, recursive, expand, revision, repo_type, token)\u001B[0m\n\u001B[0;32m   3319\u001B[0m encoded_path_in_repo \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m quote(path_in_repo, safe\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m path_in_repo \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3320\u001B[0m tree_url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mendpoint\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/api/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrepo_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124ms/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrepo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/tree/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrevision\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mencoded_path_in_repo\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 3321\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m path_info \u001B[38;5;129;01min\u001B[39;00m paginate(path\u001B[38;5;241m=\u001B[39mtree_url, headers\u001B[38;5;241m=\u001B[39mheaders, params\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrecursive\u001B[39m\u001B[38;5;124m\"\u001B[39m: recursive, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexpand\u001B[39m\u001B[38;5;124m\"\u001B[39m: expand}):\n\u001B[0;32m   3322\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m (RepoFile(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpath_info) \u001B[38;5;28;01mif\u001B[39;00m path_info[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m RepoFolder(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpath_info))\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\huggingface_hub\\utils\\_pagination.py:36\u001B[0m, in \u001B[0;36mpaginate\u001B[1;34m(path, params, headers)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fetch a list of models/datasets/spaces and paginate through results.\u001B[39;00m\n\u001B[0;32m     29\u001B[0m \n\u001B[0;32m     30\u001B[0m \u001B[38;5;124;03mThis is using the same \"Link\" header format as GitHub.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;124;03m- https://docs.github.com/en/rest/guides/traversing-with-pagination#link-header\u001B[39;00m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     35\u001B[0m session \u001B[38;5;241m=\u001B[39m get_session()\n\u001B[1;32m---> 36\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     37\u001B[0m hf_raise_for_status(r)\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m r\u001B[38;5;241m.\u001B[39mjson()\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\httpx\\_client.py:1053\u001B[0m, in \u001B[0;36mClient.get\u001B[1;34m(self, url, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001B[0m\n\u001B[0;32m   1036\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mget\u001B[39m(\n\u001B[0;32m   1037\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1038\u001B[0m     url: URL \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1046\u001B[0m     extensions: RequestExtensions \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1047\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Response:\n\u001B[0;32m   1048\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1049\u001B[0m \u001B[38;5;124;03m    Send a `GET` request.\u001B[39;00m\n\u001B[0;32m   1050\u001B[0m \n\u001B[0;32m   1051\u001B[0m \u001B[38;5;124;03m    **Parameters**: See `httpx.request`.\u001B[39;00m\n\u001B[0;32m   1052\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1053\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1054\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mGET\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1055\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1056\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1057\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1058\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcookies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcookies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1059\u001B[0m \u001B[43m        \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1060\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1061\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1062\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextensions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextensions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1063\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\httpx\\_client.py:825\u001B[0m, in \u001B[0;36mClient.request\u001B[1;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001B[0m\n\u001B[0;32m    810\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(message, \u001B[38;5;167;01mDeprecationWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m    812\u001B[0m request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuild_request(\n\u001B[0;32m    813\u001B[0m     method\u001B[38;5;241m=\u001B[39mmethod,\n\u001B[0;32m    814\u001B[0m     url\u001B[38;5;241m=\u001B[39murl,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    823\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mextensions,\n\u001B[0;32m    824\u001B[0m )\n\u001B[1;32m--> 825\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\httpx\\_client.py:914\u001B[0m, in \u001B[0;36mClient.send\u001B[1;34m(self, request, stream, auth, follow_redirects)\u001B[0m\n\u001B[0;32m    910\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_timeout(request)\n\u001B[0;32m    912\u001B[0m auth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_request_auth(request, auth)\n\u001B[1;32m--> 914\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_handling_auth\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    915\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    916\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    918\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhistory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    919\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    920\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    921\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\httpx\\_client.py:942\u001B[0m, in \u001B[0;36mClient._send_handling_auth\u001B[1;34m(self, request, auth, follow_redirects, history)\u001B[0m\n\u001B[0;32m    939\u001B[0m request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(auth_flow)\n\u001B[0;32m    941\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 942\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_handling_redirects\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    943\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    944\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    945\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhistory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhistory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    946\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    947\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    948\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\httpx\\_client.py:979\u001B[0m, in \u001B[0;36mClient._send_handling_redirects\u001B[1;34m(self, request, follow_redirects, history)\u001B[0m\n\u001B[0;32m    976\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_hooks[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequest\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m    977\u001B[0m     hook(request)\n\u001B[1;32m--> 979\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_single_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    980\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    981\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_hooks[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\httpx\\_client.py:1014\u001B[0m, in \u001B[0;36mClient._send_single_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m   1009\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m   1010\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempted to send an async request with a sync Client instance.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1011\u001B[0m     )\n\u001B[0;32m   1013\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request\u001B[38;5;241m=\u001B[39mrequest):\n\u001B[1;32m-> 1014\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mtransport\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1016\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response\u001B[38;5;241m.\u001B[39mstream, SyncByteStream)\n\u001B[0;32m   1018\u001B[0m response\u001B[38;5;241m.\u001B[39mrequest \u001B[38;5;241m=\u001B[39m request\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:249\u001B[0m, in \u001B[0;36mHTTPTransport.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    235\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mhttpcore\u001B[39;00m\n\u001B[0;32m    237\u001B[0m req \u001B[38;5;241m=\u001B[39m httpcore\u001B[38;5;241m.\u001B[39mRequest(\n\u001B[0;32m    238\u001B[0m     method\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mmethod,\n\u001B[0;32m    239\u001B[0m     url\u001B[38;5;241m=\u001B[39mhttpcore\u001B[38;5;241m.\u001B[39mURL(\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    247\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mextensions,\n\u001B[0;32m    248\u001B[0m )\n\u001B[1;32m--> 249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[0;32m    250\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pool\u001B[38;5;241m.\u001B[39mhandle_request(req)\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resp\u001B[38;5;241m.\u001B[39mstream, typing\u001B[38;5;241m.\u001B[39mIterable)\n",
      "File \u001B[1;32mD:\\Python\\lib\\contextlib.py:153\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__exit__\u001B[1;34m(self, typ, value, traceback)\u001B[0m\n\u001B[0;32m    151\u001B[0m     value \u001B[38;5;241m=\u001B[39m typ()\n\u001B[0;32m    152\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 153\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mthrow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtyp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraceback\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m    155\u001B[0m     \u001B[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001B[39;00m\n\u001B[0;32m    156\u001B[0m     \u001B[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001B[39;00m\n\u001B[0;32m    157\u001B[0m     \u001B[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001B[39;00m\n\u001B[0;32m    158\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m exc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m value\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:118\u001B[0m, in \u001B[0;36mmap_httpcore_exceptions\u001B[1;34m()\u001B[0m\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m    117\u001B[0m message \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(exc)\n\u001B[1;32m--> 118\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m mapped_exc(message) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mexc\u001B[39;00m\n",
      "\u001B[1;31mConnectTimeout\u001B[0m: timed out"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "d7b03919-51c8-4da7-be40-2e4b61606379",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T11:08:35.354925900Z",
     "start_time": "2026-02-12T09:31:04.220205Z"
    }
   },
   "source": [
    "model"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2、IA3Config配置",
   "id": "8d83b032ec8c33f5"
  },
  {
   "cell_type": "code",
   "id": "dccc2f10-2add-4e62-8120-f6eddef20202",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T11:08:35.374106900Z",
     "start_time": "2026-02-12T09:31:04.331613Z"
    }
   },
   "source": [
    "config = IA3Config(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    init_ia3_weights=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "9c8fcd78-8fdc-479b-893f-b245a973807b",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "def print_module_names(model, prefix=\"\"):\n",
    "    for name, module in model.named_children():\n",
    "        full_name = f\"{prefix}.{name}\" if prefix else name\n",
    "        print(full_name)\n",
    "        print_module_names(module, full_name)\n",
    "\n",
    "print_module_names(model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b9c97260-7560-4b35-9529-c5f0e2713f02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T11:08:35.375117900Z",
     "start_time": "2026-02-12T09:30:48.891506Z"
    }
   },
   "source": [
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()  # 打印可训练参数"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mget_peft_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIA3Config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39mprint_trainable_parameters()  \u001B[38;5;66;03m# 打印可训练参数\u001B[39;00m\n",
      "File \u001B[1;32mE:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\peft\\mapping_func.py:122\u001B[0m, in \u001B[0;36mget_peft_model\u001B[1;34m(model, peft_config, adapter_name, mixed, autocast_adapter_dtype, revision, low_cpu_mem_usage)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m peft_config\u001B[38;5;241m.\u001B[39mtask_type \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m MODEL_TYPE_TO_PEFT_MODEL_MAPPING\u001B[38;5;241m.\u001B[39mkeys() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m peft_config\u001B[38;5;241m.\u001B[39mis_prompt_learning:\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m PeftModel(\n\u001B[0;32m    115\u001B[0m         model,\n\u001B[0;32m    116\u001B[0m         peft_config,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    119\u001B[0m         low_cpu_mem_usage\u001B[38;5;241m=\u001B[39mlow_cpu_mem_usage,\n\u001B[0;32m    120\u001B[0m     )\n\u001B[1;32m--> 122\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mMODEL_TYPE_TO_PEFT_MODEL_MAPPING\u001B[49m\u001B[43m[\u001B[49m\u001B[43mpeft_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtask_type\u001B[49m\u001B[43m]\u001B[49m(\n\u001B[0;32m    123\u001B[0m     model,\n\u001B[0;32m    124\u001B[0m     peft_config,\n\u001B[0;32m    125\u001B[0m     adapter_name\u001B[38;5;241m=\u001B[39madapter_name,\n\u001B[0;32m    126\u001B[0m     autocast_adapter_dtype\u001B[38;5;241m=\u001B[39mautocast_adapter_dtype,\n\u001B[0;32m    127\u001B[0m     low_cpu_mem_usage\u001B[38;5;241m=\u001B[39mlow_cpu_mem_usage,\n\u001B[0;32m    128\u001B[0m )\n",
      "\u001B[1;31mKeyError\u001B[0m: None"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "31ba0d29-e4bf-4b71-a829-beafd8a80743",
   "metadata": {},
   "source": "## 3、加载数据集"
  },
  {
   "cell_type": "code",
   "id": "547b3f06-5b3e-4761-8e6a-35adf9cd6ef5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T11:08:35.375675400Z",
     "start_time": "2026-02-12T03:52:06.262146Z"
    }
   },
   "source": "data=load_dataset('json',data_files='../../dataset/chinese_law_ft_dataset.json',split=\"train[:1000]\")",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "9557f41d-a593-42d6-ae4f-4d71d406a828",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T11:08:35.375675400Z",
     "start_time": "2026-02-12T03:52:07.616753Z"
    }
   },
   "source": [
    "dataset=data.train_test_split(\n",
    "    train_size=0.7,\n",
    "    shuffle=True,\n",
    "    seed=7\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T11:08:35.375675400Z",
     "start_time": "2026-02-12T03:52:07.680538Z"
    }
   },
   "cell_type": "code",
   "source": "dataset",
   "id": "db5af052fc376d00",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'id'],\n",
       "        num_rows: 700\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'id'],\n",
       "        num_rows: 300\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "f6de150f-a3ab-4bda-b37c-02cab4a71c76",
   "metadata": {},
   "source": "## 4、数据预处理"
  },
  {
   "cell_type": "code",
   "id": "8afdb899-12bc-4ad0-855c-ae3ac1107171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T11:08:35.375675400Z",
     "start_time": "2026-02-12T03:52:07.729217Z"
    }
   },
   "source": [
    "def process_fun(example):\n",
    "    content=[]\n",
    "    for instruction,input,output in zip(example['instruction'],example['input'],example['output']):\n",
    "        if input.strip():\n",
    "            text=f'Human:{instruction}\\n{input}\\nAI:{output}'\n",
    "            content.append(text)\n",
    "        else:\n",
    "            text=f'Human:{instruction}\\nAI:{output}'\n",
    "            content.append(text)\n",
    "    \n",
    "    encoded = tokenizer(\n",
    "        content,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    labels = encoded[\"input_ids\"].clone()\n",
    "    for index,text in enumerate(content):\n",
    "        answer_start=text.find('AI:')+len('AI:')\n",
    "        question=text[:answer_start]\n",
    "        question_ids=tokenizer.encode(question, add_special_tokens=False)\n",
    "        question_length=len(question_ids)\n",
    "        labels[index,:question_length]=-100\n",
    "    return {\n",
    "        \"input_ids\": encoded[\"input_ids\"],\n",
    "        \"attention_mask\": encoded[\"attention_mask\"],\n",
    "        \"labels\": labels\n",
    "    }\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "d30dc912-ef36-469e-ab5e-57dd2734014c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T11:08:35.376714400Z",
     "start_time": "2026-02-12T03:52:07.840670Z"
    }
   },
   "source": [
    "train_process_data=dataset['train'].map(process_fun,batched=True,remove_columns=dataset['train'].column_names)\n",
    "test_process_data=dataset['test'].map(process_fun,batched=True,remove_columns=dataset['test'].column_names)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "28d119c8-26ca-4870-999e-4b7748b17f12",
   "metadata": {},
   "source": "## 5、模型训练配置"
  },
  {
   "cell_type": "code",
   "id": "a566cae3-b5af-455c-b138-dc892cbd0ed2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T11:08:35.376714400Z",
     "start_time": "2026-02-12T03:52:28.438242Z"
    }
   },
   "source": [
    "# 定义训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../../models/IA3_tuning\",\n",
    "    logging_steps=10,\n",
    "    logging_dir='./runs',\n",
    "    eval_strategy='epoch',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_loss',\n",
    "    gradient_accumulation_steps=4,  # 如果GPU内存有限\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`logging_dir` is deprecated and will be removed in v5.2. Please set `TENSORBOARD_LOGGING_DIR` instead.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "eba32532-f06d-4eb9-b57d-b70f1ff6105d",
   "metadata": {},
   "source": "## 6、训练模型"
  },
  {
   "cell_type": "code",
   "id": "05c4ee6d-3ae2-4dc8-b3f1-1e1756d3c211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T11:08:35.376714400Z",
     "start_time": "2026-02-12T03:52:31.731568Z"
    }
   },
   "source": [
    "trainer=Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=test_process_data,\n",
    "    train_dataset=train_process_data,\n",
    "    data_collator=default_data_collator,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "74ae5260-bd74-43fb-a110-8f88ad05c5eb",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2026-02-12T11:08:35.376714400Z",
     "start_time": "2026-02-12T03:52:33.129334Z"
    }
   },
   "source": [
    "trainer.train()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bf5e2c2-90ed-4eed-98c3-5b6ab85d1207",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('./lora_train_qwen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa2c9ab-25a0-4245-9a7b-49ed52df21a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
