{
 "cells": [
  {
   "cell_type": "code",
   "id": "ad546fcc-ab06-406d-8be3-e9edc488964d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T05:55:00.358171Z",
     "start_time": "2026-02-14T05:54:55.406234Z"
    }
   },
   "source": [
    "from peft import prepare_model_for_kbit_training,LoraConfig,get_peft_model,TaskType\n",
    "from transformers import AutoModelForCausalLM,AutoTokenizer,TrainingArguments,Trainer,default_data_collator,BitsAndBytesConfig\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "E:\\web\\LLM-tuning\\.venv\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "6bcb38da-f0ab-4c77-9789-3ae966c0e754",
   "metadata": {},
   "source": [
    "### QLoRa配置"
   ]
  },
  {
   "cell_type": "code",
   "id": "a756cb70-3930-4d36-a14c-d8236e6c22ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T05:55:00.388440Z",
     "start_time": "2026-02-14T05:55:00.373303Z"
    }
   },
   "source": [
    "_compute_dtype_map = {\n",
    "    'fp32': torch.float32,\n",
    "    'fp16': torch.float16,\n",
    "    'bf16': torch.bfloat16\n",
    "}\n",
    "\n",
    "# QLoRA 量化配置\n",
    "q_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                              bnb_4bit_quant_type='nf4',\n",
    "                              bnb_4bit_use_double_quant=True,\n",
    "                              bnb_4bit_compute_dtype=_compute_dtype_map['fp32'],\n",
    "                             )"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "c1c07780-6823-41a0-b188-6d82e4f37b0b",
   "metadata": {},
   "source": [
    "### 模型加载"
   ]
  },
  {
   "cell_type": "code",
   "id": "5f18d7b6-e5ca-4f18-adcc-c10ebf58f37d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T05:55:17.522980Z",
     "start_time": "2026-02-14T05:55:00.450818Z"
    }
   },
   "source": [
    "model_name=\"Qwen/Qwen3-0.6B\"\n",
    "model=AutoModelForCausalLM.from_pretrained(model_name,device_map='auto',torch_dtype=\"auto\",quantization_config=q_config)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_name)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 311/311 [00:02<00:00, 123.67it/s, Materializing param=model.norm.weight]                              \n",
      "The tied weights mapping and config for this model specifies to tie model.embed_tokens.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "a98b6008-4350-4b52-943b-de29b7013539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T05:55:17.679935Z",
     "start_time": "2026-02-14T05:55:17.601321Z"
    }
   },
   "source": [
    "kbit_model = prepare_model_for_kbit_training(model)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "7db597ea-6722-4023-8b34-afd8dd10e18a",
   "metadata": {},
   "source": [
    "### LoRa配置"
   ]
  },
  {
   "cell_type": "code",
   "id": "e817976d-1a5b-424c-b823-f0a58ba18a29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T05:55:17.696047Z",
     "start_time": "2026-02-14T05:55:17.685941Z"
    }
   },
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=4,  # LoRA矩阵的秩\n",
    "    lora_alpha=32,  # LoRA alpha参数\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],  # 要应用LoRA的模块\n",
    "    lora_dropout=0.05,  # Dropout概率\n",
    "    bias=\"none\",  # 是否训练偏置\n",
    "    task_type=\"CAUSAL_LM\",  # 任务类型\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "3ffa84e7-c530-4938-9644-0b3828c89d9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T05:55:17.948742Z",
     "start_time": "2026-02-14T05:55:17.728738Z"
    }
   },
   "source": [
    "qlora_model = get_peft_model(kbit_model, lora_config)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "d9877371-0673-4a4a-8db2-7b5b49c6f76d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T05:55:18.012073Z",
     "start_time": "2026-02-14T05:55:17.997072Z"
    }
   },
   "source": [
    "qlora_model.print_trainable_parameters()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,146,880 || all params: 752,779,264 || trainable%: 0.1524\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "e6431501-a72f-4c77-8334-36756ba1a7ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T05:55:18.075195Z",
     "start_time": "2026-02-14T05:55:18.060555Z"
    }
   },
   "source": [
    "qlora_model"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Qwen3ForCausalLM(\n",
       "      (model): Qwen3Model(\n",
       "        (embed_tokens): Embedding(151936, 1024)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=1024, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=4, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=4, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=1024, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=4, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=4, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=1024, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=4, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=4, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=4, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=4, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): Linear4bit(in_features=1024, out_features=3072, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=1024, out_features=3072, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (rotary_emb): Qwen3RotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "109032c7-38b8-480e-9470-724ddb887676",
   "metadata": {},
   "source": [
    "### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "id": "80fc5eeb-5a36-42e7-bc9d-63fdc493ff8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T05:55:19.921581Z",
     "start_time": "2026-02-14T05:55:18.123411Z"
    }
   },
   "source": "data=load_dataset('json',data_files='../../dataset/chinese_law_ft_dataset.json',split=\"train[:1000]\")",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "d359c356-519f-42bf-a614-166c831b2d5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T05:55:19.984012Z",
     "start_time": "2026-02-14T05:55:19.969007Z"
    }
   },
   "source": [
    "dataset = data.train_test_split(\n",
    "    train_size=0.7,\n",
    "    shuffle=True,\n",
    "    seed=7\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T05:55:20.046239Z",
     "start_time": "2026-02-14T05:55:20.031247Z"
    }
   },
   "cell_type": "code",
   "source": "dataset",
   "id": "f848ee9de7cc721b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'id'],\n",
       "        num_rows: 700\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'id'],\n",
       "        num_rows: 300\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "d029b036-eaaf-4143-b885-bac9e1486945",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "id": "1d15b761-2db8-4ec9-b778-c411f3400d90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T05:55:20.108515Z",
     "start_time": "2026-02-14T05:55:20.094312Z"
    }
   },
   "source": [
    "def process_fun(example):\n",
    "    content=[]\n",
    "    for instruction,input,output in zip(example['instruction'],example['input'],example['output']):\n",
    "        if input.strip():\n",
    "            text=f'Human:{instruction}\\n{input}\\nAI:{output}'\n",
    "            content.append(text)\n",
    "        else:\n",
    "            text=f'Human:{instruction}\\nAI:{output}'\n",
    "            content.append(text)\n",
    "    \n",
    "    encoded = tokenizer(\n",
    "        content,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    labels = encoded[\"input_ids\"].clone()\n",
    "    for index,text in enumerate(content):\n",
    "        answer_start=text.find('AI:')+len('AI:')\n",
    "        question=text[:answer_start]\n",
    "        question_ids=tokenizer.encode(question, add_special_tokens=False)\n",
    "        question_length=len(question_ids)\n",
    "        labels[index,:question_length]=-100\n",
    "    return {\n",
    "        \"input_ids\": encoded[\"input_ids\"],\n",
    "        \"attention_mask\": encoded[\"attention_mask\"],\n",
    "        \"labels\": labels\n",
    "    }\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "8c2db0bc-0598-4f1f-8745-7024b67d6caa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T05:55:22.281898Z",
     "start_time": "2026-02-14T05:55:20.156634Z"
    }
   },
   "source": [
    "train_process_data=dataset['train'].map(process_fun,batched=True,remove_columns=dataset['train'].column_names)\n",
    "test_process_data=dataset['test'].map(process_fun,batched=True,remove_columns=dataset['test'].column_names)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "e9388b5d-b529-4254-8e0b-c4463f87b917",
   "metadata": {},
   "source": [
    "### 训练超参数"
   ]
  },
  {
   "cell_type": "code",
   "id": "2ad09c0c-6f19-426c-bb74-a5937ce3a271",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T05:55:22.438608Z",
     "start_time": "2026-02-14T05:55:22.361951Z"
    }
   },
   "source": [
    "# 定义训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../../models/qlora\",\n",
    "    logging_steps=100,\n",
    "    logging_dir='./runs',\n",
    "    eval_strategy='epoch',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    metric_for_best_model='eval_loss',\n",
    "    gradient_accumulation_steps=4,  # 如果GPU内存有限\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`logging_dir` is deprecated and will be removed in v5.2. Please set `TENSORBOARD_LOGGING_DIR` instead.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "df2afcab-d377-4718-86f2-6b6a743b0443",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "id": "b522e06f-e260-44d6-8b50-fd042896bd3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T05:56:06.400226Z",
     "start_time": "2026-02-14T05:56:06.376227Z"
    }
   },
   "source": [
    "trainer=Trainer(\n",
    "    model=qlora_model,\n",
    "    args=training_args,\n",
    "    eval_dataset=test_process_data,\n",
    "    train_dataset=train_process_data,\n",
    "    data_collator=default_data_collator,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "cc233cd3-b630-4e86-a9e5-1d92cb708f16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:26:03.919467Z",
     "start_time": "2026-02-14T05:56:12.077851Z"
    }
   },
   "source": [
    "trainer.train()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 29:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>8.024446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.540305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.521588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=66, training_loss=7.227429939038826, metrics={'train_runtime': 1791.6738, 'train_samples_per_second': 1.172, 'train_steps_per_second': 0.037, 'total_flos': 3852635996160000.0, 'train_loss': 7.227429939038826, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "33789570-c6f2-4426-832b-7dceff3787c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:26:18.191941Z",
     "start_time": "2026-02-14T06:26:16.366058Z"
    }
   },
   "source": "trainer.save_model('../../models/qlora')",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ac9d17c38214545e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
