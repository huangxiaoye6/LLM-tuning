{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# AWQ量化",
   "id": "c091eb158f66b983"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from awq import AutoAWQForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AwqConfig, AutoConfig\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "b76b0c70196d4a1c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1、加载模型",
   "id": "bd85629ee93c360d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_name=\"Qwen/Qwen3-0.6B\"\n",
    "model = AutoAWQForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"
   ],
   "id": "b0754cc52b987911"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2、配置quant_config",
   "id": "83633a90b37d3de9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "quant_path = \"../../models/qwen3-7b-awq\"\n",
    "quant_config = {\"zero_point\": True, \"q_group_size\": 128, \"w_bit\": 4, \"version\":\"GEMM\"}"
   ],
   "id": "395f63f489d461cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3、开始模型量化",
   "id": "cc8bd18a5d788d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.quantize(tokenizer, quant_config=quant_config)",
   "id": "50016429253b8e18"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4、调整量化配置以兼容 Transformers",
   "id": "2d388ff69aa0da88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "quantization_config = AwqConfig(\n",
    "    bits=quant_config[\"w_bit\"],\n",
    "    group_size=quant_config[\"q_group_size\"],\n",
    "    zero_point=quant_config[\"zero_point\"],\n",
    "    version=quant_config[\"version\"].lower(),\n",
    ").to_dict()\n",
    "model.model.config.quantization_config = quantization_config"
   ],
   "id": "3dfee83e0809c497"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5、保存量化后的模型和分词器",
   "id": "64accb8048c0dc15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.save_quantized(quant_path)\n",
    "tokenizer.save_pretrained(quant_path)"
   ],
   "id": "d4c86dec42311148"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
